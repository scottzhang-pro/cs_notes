{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict({\n",
    "    'month': ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun'],\n",
    "    'eggs': [33, 22, 13, 28, 43, 55],\n",
    "    'salt': [12, 32,  9,  3,  23,  0], \n",
    "    'spam': [17, 31, 72, 20, 52, 55]\n",
    "})\n",
    "df.set_index('month', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基础"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用中括号\n",
    "df[\"eggs\"]['May']\n",
    "\n",
    "# 使用列名\n",
    "df.eggs['May']\n",
    "\n",
    "# 使用 loc\n",
    "df.loc['May', 'eggs']\n",
    "df.loc['May']['eggs']\n",
    "\n",
    "# 使用 iloc\n",
    "df.iloc[4, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eggs 列中的某些值\n",
    "df['eggs'][1:3]\n",
    "\n",
    "# eggs 列中的某个值\n",
    "df['eggs'][1]\n",
    "\n",
    "# 某些列中的所有行\n",
    "df.loc[:, 'eggs':'salt']\n",
    "\n",
    "# 某些行中所有列\n",
    "df.loc['Jan':'Feb', :]\n",
    "\n",
    "# 某些行中某些列\n",
    "df.loc['Jan':'Mar', 'eggs':'salt']\n",
    "df.loc['Jan':'Mar', ['eggs', 'salt']]  # 使用列表删选行\n",
    "\n",
    "# 使用 iloc 选择\n",
    "df.iloc[2:5, 1:]\n",
    "\n",
    "# df['eggs']  -> pandas.core.series.Series\n",
    "# df[['eggs]] -> pandas.core.frame.DataFrame\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, df.all()]           # 所有非0值\n",
    "df.loc[:, df.any()]           # 0值行\n",
    "df.loc[:, df.isnull().any()]  # 任何 na 行\n",
    "df.loc[:, df.notnull().any()] # 任何 na 行\n",
    "df.dropna(how='any')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.eggs[df.salt > 55] += 5   # 加\n",
    "df.floordiv(12)              # 类似 dataframe // other，支持fill_value\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About DataFrame Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 Series\n",
    "prices = [3, 2, 1.5, 4, 4.5]\n",
    "shares = pd.Series(prices)\n",
    "\n",
    "# 创建Series，从数组指定索引值\n",
    "days = ['Mon', 'Tue', 'Wed', 'Thur', 'Fri']\n",
    "shares = pd.Series(prices, index=days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可使用下标访问索引值，也可以切片\n",
    "shares.index[0]\n",
    "\n",
    "# 给索引起名\n",
    "shares.name = \"Share\"\n",
    "\n",
    "# 给索引赋值会出错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多重索引访问索引名\n",
    "# df.index.name  -> None\n",
    "# df.index.names -> ['a', 'b']\n",
    "\n",
    "# 按索引排序\n",
    "df.sort_index()\n",
    "\n",
    "# 指定索引的顺序进行排序\n",
    "df.reindex(['Jan', 'Apr'])\n",
    "\n",
    "# 按照另外一个dataframe index 的顺序排序\n",
    "df2 = pd.DataFrame()\n",
    "df.reindex(df2.index)\n",
    "\n",
    "# 多重索引选择，使用元组\n",
    "df.loc[('idx1','idx2'), 'col_name']\n",
    "\n",
    "# 只选择单个索引，会返回该索引内部得值（包括子索引）\n",
    "df.loc['idx1']\n",
    "\n",
    "# 使用 slice 函数，对第一层不设条件，返回第二层 ab 结果\n",
    "df.loc[slice(None), slice('a','b')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melt\n",
    "\n",
    "- Melt：适用于列中存在值，需要整理到行中的情况\n",
    "- Pivoting: 与Melt 相反，将1列中唯一的值放到不同的列上\n",
    "\n",
    "### Pivot\n",
    "\n",
    "- Pivot 根据列值 Reshape 数据，有重复值会出错\n",
    "- PivotTable 根据列值 Reshape 数据，有重复值可指定 aggregate 函数(sum, count, etc.)\n",
    "- 都可以指定多个 index 或者 columns\n",
    "\n",
    "### Stack 和 Unstack\n",
    "\n",
    "- UnStack 将行上的多 index 中的某一个放到 column 上，需要指定参数 level= '' ，即index 中的某个值；传给 level 的也可以是一个数字比如 0,1 等，取决于 index 的层数\n",
    "- Stack 将 column 上的 index 放到行上\n",
    "- 多索引中，可使用 swaplevel 方式交换两个索引的顺序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by\n",
    "\n",
    "Groupby 一般有几个步骤：\n",
    "\n",
    "- 根据某些列按其值分割成不同的组\n",
    "- 对每个组，指定内部的某些列进行操作\n",
    "- 将这些操作后的结果组合起来\n",
    "\n",
    "Groupby 有一些特殊操作方便我们使用：\n",
    "- 第一个分割组的操作，可以传入自定义的 Series, 不限定于列名\n",
    "- groupby 的时候，使用 category 类型的数据会加快速度\n",
    "- 组合组内部的操作，一般使用 mean, sum, max 等，但也可以一次指定多个函数，如 `df.groupby(['a','b']).agg('a':'sum')`, 也可以指定自定义的函数\n",
    "\n",
    "Groupby 可以和 transformation 结合使用，看下面的例子：\n",
    "\n",
    "```python\n",
    " def zscore(series):\n",
    "     \"对 Series 中的值，每一个都减去其平均值，再除以标准差\"\n",
    "    return (series - series.mean()) / series.std()\n",
    "```\n",
    "\n",
    "使用的时候，直接传入 dataframe 的某列：\n",
    "\n",
    "```python\n",
    "zscore(df['mpg']).head()\n",
    "```\n",
    "\n",
    "所以，我们也可以接 group 去使用：\n",
    "\n",
    "```python\n",
    "df.groupby('yr')['mpg'].transform(zscore).head()\n",
    "```\n",
    "\n",
    "进一步的，可以把一些操作组合起来放到一个函数:\n",
    "\n",
    "```python\n",
    "def zscore_with_year_and_name(group):\n",
    "    \"\"\"针对每一个 group，只取其中的某些列（mpg, year, name）做一些操作并组合成新的 dataframe\n",
    "       对于操作：mpg，算 zscore; yr 重命名为 year; name 不操作.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({\n",
    "            'mpg': zscore(group['mpg']),\n",
    "            'year': group['yr'],\n",
    "            'name': group['name']\n",
    "        })\n",
    "    return df\n",
    "\n",
    "df.groupby('yr').apply(zscore_with_year_and_name).head()\n",
    "```\n",
    "\n",
    "有时候你分组操作后，需要再进行 filter 操作，这需要拿到 groupby 之后的对象进行遍历操作。\n",
    "\n",
    "首先我们来看看 groupby 操作后得到的对象：\n",
    "\n",
    "```python\n",
    "splitting = auto.groupby('yr')\n",
    "\n",
    "type(splitting)\n",
    "# pandas.core.groupby.DataFrameGroupBy\n",
    "\n",
    "type(splitting.groups)\n",
    "# dict\n",
    "\n",
    "print(splitting.groups.keys())\n",
    "# dict_keys([70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82])\n",
    "```\n",
    "\n",
    "你可以对 group 对象进行遍历:\n",
    "\n",
    "```python\n",
    "for groupname, group in splitting:\n",
    "   avg = group['mpg'].mean()\n",
    "   print(group_name, avg)\n",
    "```\n",
    "\n",
    "对于一个 group 对象，你也可以对其使用 loc 操作，所以在内部我们可以进行 filter:\n",
    "\n",
    "```python\n",
    "# 对 group filter，只找出 name 包含 chevrolet 的组，取出其 mpg 列求 mean\n",
    "# 返回的是单个值\n",
    "group.loc[group['name'].str.contains('chevrolet'), 'mpg'].mean()\n",
    "```\n",
    "\n",
    "```python\n",
    "# 结合操作，得到一个 Series\n",
    "chevy_means = {\n",
    "    year: group.loc[group['name'].str.contains('chevrolet'),'mpg'].mean()\n",
    "    for year, group in splitting\n",
    "}\n",
    "pd.Series(chevy_means)\n",
    "```\n",
    "\n",
    "一组条件，也可以当作 groupby 的列，如:\n",
    "\n",
    "\n",
    "```python\n",
    "# chevy 一组 True, False，其值反映了df name列中包含 chevrolet 的行\n",
    "chevy = df['name'].str.contains('chevrolet')\n",
    "\n",
    "# 将 chevy 作为 groupby 条件\n",
    "df.groupby(['yr', chevy])['mpg'].mean()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat\n",
    "\n",
    "- Concat 时可以指定 index，如 `pd.concat([rain2013, rain2014], keys=[2013, 2014], axis=0)`，如果两个 df 本来就有 index，则会产生多 index\n",
    "- index 也可以在 column 上，如 `pd.concat([rain2013, rain2014], keys=[2013, 2014], axis='columns')`\n",
    "- 可以将两个数组左右拼接到一起，可以使用 `np.hstack([B, A])` 或者 `np.concatenate([B, A], axis=1)`\n",
    "\n",
    "### Merge\n",
    "\n",
    "- merge 时，指定 suffixis 参数来区分来自不同 dataframe 的列\n",
    "- 对于特殊的 merge，可以了解 `pandas.merge_asof` 和 `pandas.merge_ordered` 方法"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63c507700e54c2628652ffbdabcd7e94be88940c185c40088727646e02fde70b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('dev': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
