{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing in Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automated testing is a hot topic especially in CI/CD, there are many tools, today let's talk about 'pytest'.\n",
    "\n",
    "Pytest features:\n",
    "\n",
    "\t- Test code more readable\n",
    "\t- Support assert statements\n",
    "\t- Compare with unitest, Pytest Updated more frequently\n",
    "\t- Have a consistent style across all Python project (like Django and Flask)\n",
    "\n",
    "\n",
    "Automated tests should be:\n",
    "\n",
    "\t- Fast\n",
    "\t- Isolated/independent\n",
    "\t- Deterministic/repeatable\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mocking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we explain mocking in Python, you need understand what is `**args` and `**kwargs`. Both keywords are special syntax in Python that allows a function to accept a variable number of keyword arguments\n",
    "- `**args`, which you can use it(args) as a list inside a function\n",
    "- `**kwargs` which you can use it(kwargs) as a dict inside a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def args_func(*args):\n",
    "    for arg in args:\n",
    "        print(arg)\n",
    "\n",
    "args_func([1, 2, 3], [4, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kwargs_func(**kwargs):\n",
    "    for k, v in kwargs.items():\n",
    "        print(k, v)\n",
    "kwargs_func(name=\"scott\", age=27)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is two mocking examples that replace a attribute and a method in runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock a attribute\n",
    "def test_my_function_mock_attr(monkeypatch):\n",
    "    class MyClass:\n",
    "        my_attr = 42\n",
    "    \n",
    "    def mock_my_attr():\n",
    "        return 99\n",
    "    \n",
    "    monkeypatch.setattr(MyClass, \"my_attr\", mock_my_attr)\n",
    "\n",
    "    assert MyClass().my_attr == 99\n",
    "\n",
    "# Mock a function\n",
    "def test_my_function_mock_method(monkeypatch):\n",
    "    class MyClass:\n",
    "        def my_method(self):\n",
    "            return 42\n",
    "    \n",
    "    def mock_my_method():\n",
    "        return 99\n",
    "    \n",
    "    monkeypatch.setattr(MyClass, \"my_method\", mock_my_method)\n",
    "\n",
    "    assert MyClass().my_attr == 99"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest import mock\n",
    "\n",
    "import requests\n",
    "from requests import Response\n",
    "\n",
    "\n",
    "def get_my_ip():\n",
    "    response = requests.get(\n",
    "        'http://ipinfo.io/json'\n",
    "    )\n",
    "    return response.json()['ip']\n",
    "\n",
    "\n",
    "def test_get_my_ip(monkeypatch):\n",
    "    my_ip = '123.123.123.123'\n",
    "    # creates a mock object with the same properties and methods\n",
    "    # as the object passed as a parameter\n",
    "    response = mock.create_autospec(Response)\n",
    "    response.json.return_value = {'ip': my_ip}\n",
    "\n",
    "    # setattr method allows you to dynamically replace an attribute\n",
    "    # or method of an object with a new value or method\n",
    "    monkeypatch.setattr(\n",
    "        requests,\n",
    "        'get',\n",
    "        lambda *args, **kwargs: response\n",
    "    )\n",
    "\n",
    "    assert get_my_ip() == my_ip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Coverage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code coverage is a metric which tells you the ratio between the executed lines code(during test) and total lines code.\n",
    "\n",
    "there is a plugin for this: `pytest-cov`, once installed, to run tests with coverage reporting, add the `--cov` option:\n",
    "\n",
    "```shell\n",
    "python -m pytest --cov=.\n",
    "```\n",
    "\n",
    "In the output:\n",
    "\n",
    "- Stmts, number of lines of code\n",
    "- Miss, number of lines that weren't excuted by the test\n",
    "- Cover, Coverage percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Muatation Testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muatation means the tools will iterates through each line of you code, making small changes to test effectiveness or robustness.\n",
    "\n",
    "For example, following code:\n",
    "```python\n",
    "if x > y:\n",
    "    z = 50\n",
    "else:\n",
    "    z = 100\n",
    "```\n",
    "\n",
    "mutation tool may change the operotor from > to >= like so:\n",
    "\n",
    "```python\n",
    "if x >= y:\n",
    "    z = 50\n",
    "else:\n",
    "    z = 100\n",
    "```\n",
    "> Mutation testing tools for Python are not as mature as some of the others out there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis testing generates a wide-range of random data that's dependent on previous tests runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment(num: int) -> int:\n",
    "    return num + 1\n",
    "\n",
    "# You need many test data, example here.\n",
    "# if you don't write enought code, then you test coverage isn't enought\n",
    "import pytest\n",
    "@pytest.mark.parametrize(\n",
    "    'number, result',\n",
    "    [\n",
    "        (-2, -1),\n",
    "        (0, 1),\n",
    "        (3, 4),\n",
    "        (101234, 101235),\n",
    "    ]\n",
    ")\n",
    "def test_increment(number, result):\n",
    "    assert increment(number) == result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with hypothesis tools, they can generate data for you to test\n",
    "from hypothesis import given\n",
    "import hypothesis.strategies as st\n",
    "\n",
    "\n",
    "@given(st.integers())\n",
    "def test_add_one(num):\n",
    "    assert increment(num) == num - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type Checking"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests are code, You do need maintain and refactor them, but remember to keep you tests short, simple and straight.\n",
    "\n",
    "Don't Over test your code.\n",
    "\n",
    "Runtime (or dynamic) type checkers, like Typeguard and pydantic, can help to minimize the number of tests. Let's take a look at an example of this with pydantic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class User:\n",
    "\n",
    "    def __init__(self, email: str):\n",
    "        self.email = email\n",
    "\n",
    "\n",
    "user = User(email='john@doe.com')\n",
    "user.email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, EmailStr\n",
    "\n",
    "\n",
    "class User(BaseModel):\n",
    "    email: EmailStr\n",
    "\n",
    "\n",
    "# will be validated by pydantic before every new User instance is created\n",
    "user = User(email='john@doe.com')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
